{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to collect the review data on a subsidiary company of Centrica, British Gas. The data collection is performed by the process of web scraping from the customer review website, https://uk.trustpilot.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to scrape Trustpilot for British Gas\n",
    "def BG_scrape(address, page_num):\n",
    "    # empty dataframes to be filled later\n",
    "    full_df = pd.DataFrame()\n",
    "    rating_df = pd.DataFrame()\n",
    "    review_df = pd.DataFrame()\n",
    "    date_df = pd.DataFrame()\n",
    "    \n",
    "    with urllib.request.urlopen(address) as url1:\n",
    "        page1 = url1.read()\n",
    "    soup1 = BeautifulSoup(page1, 'html.parser')\n",
    "\n",
    "    for i in range(0, page_num):\n",
    "        print(str(i + 1) + '/' + str(page_num) + ' pages parsed') # keep track of pages parsed\n",
    "        sleep(2) # to not spam the server\n",
    "        url = address + str(i + 1)\n",
    "        page = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        \n",
    "        # finding all ratings\n",
    "        rating_list = []\n",
    "        rating_parent = soup.find_all('div', {'class':'review-info__header__verified'}) # only getting stars from reviews\n",
    "        for ratings in rating_parent:\n",
    "            rating = str(ratings.find_all('div', {'class': 'star-rating'}))\n",
    "            rating_list.append(rating[37]) # the rating value is on index 37\n",
    "        rating_df = rating_df.append(rating_list, ignore_index=True)\n",
    "        \n",
    "        # finding all reviews\n",
    "        review_list = []\n",
    "        review = soup.find_all(class_='review-info__body__text')\n",
    "        for r in review:\n",
    "            review_list.append(r.text.strip('\\n'))\n",
    "        review_df = review_df.append(review_list, ignore_index=True)\n",
    "        \n",
    "        # finding all dates\n",
    "        date_list = []\n",
    "        date_parent = soup.find_all('div', {'class': 'header__verified__date'}) # only dates from reviews\n",
    "        for dates in date_parent:\n",
    "            date = dates.find('time')\n",
    "            date_list.append(date['datetime'])\n",
    "        date_df = date_df.append(date_list, ignore_index=True)\n",
    "        \n",
    "        # combining all dataframes\n",
    "        full_df = pd.concat([rating_df, review_df, date_df], axis=1, ignore_index=True)\n",
    "        full_df.columns = ['rating', 'reviews', 'date']\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data on British Gas are collected from 3713 unique reviews (as of 08/07/2018) available at https://uk.trustpilot.com/review/www.britishgas.co.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/186 pages parsed\n",
      "2/186 pages parsed\n",
      "3/186 pages parsed\n",
      "4/186 pages parsed\n",
      "5/186 pages parsed\n",
      "6/186 pages parsed\n",
      "7/186 pages parsed\n",
      "8/186 pages parsed\n",
      "9/186 pages parsed\n",
      "10/186 pages parsed\n",
      "11/186 pages parsed\n",
      "12/186 pages parsed\n",
      "13/186 pages parsed\n",
      "14/186 pages parsed\n",
      "15/186 pages parsed\n",
      "16/186 pages parsed\n",
      "17/186 pages parsed\n",
      "18/186 pages parsed\n",
      "19/186 pages parsed\n",
      "20/186 pages parsed\n",
      "21/186 pages parsed\n",
      "22/186 pages parsed\n",
      "23/186 pages parsed\n",
      "24/186 pages parsed\n",
      "25/186 pages parsed\n",
      "26/186 pages parsed\n",
      "27/186 pages parsed\n",
      "28/186 pages parsed\n",
      "29/186 pages parsed\n",
      "30/186 pages parsed\n",
      "31/186 pages parsed\n",
      "32/186 pages parsed\n",
      "33/186 pages parsed\n",
      "34/186 pages parsed\n",
      "35/186 pages parsed\n",
      "36/186 pages parsed\n",
      "37/186 pages parsed\n",
      "38/186 pages parsed\n",
      "39/186 pages parsed\n",
      "40/186 pages parsed\n",
      "41/186 pages parsed\n",
      "42/186 pages parsed\n",
      "43/186 pages parsed\n",
      "44/186 pages parsed\n",
      "45/186 pages parsed\n",
      "46/186 pages parsed\n",
      "47/186 pages parsed\n",
      "48/186 pages parsed\n",
      "49/186 pages parsed\n",
      "50/186 pages parsed\n",
      "51/186 pages parsed\n",
      "52/186 pages parsed\n",
      "53/186 pages parsed\n",
      "54/186 pages parsed\n",
      "55/186 pages parsed\n",
      "56/186 pages parsed\n",
      "57/186 pages parsed\n",
      "58/186 pages parsed\n",
      "59/186 pages parsed\n",
      "60/186 pages parsed\n",
      "61/186 pages parsed\n",
      "62/186 pages parsed\n",
      "63/186 pages parsed\n",
      "64/186 pages parsed\n",
      "65/186 pages parsed\n",
      "66/186 pages parsed\n",
      "67/186 pages parsed\n",
      "68/186 pages parsed\n",
      "69/186 pages parsed\n",
      "70/186 pages parsed\n",
      "71/186 pages parsed\n",
      "72/186 pages parsed\n",
      "73/186 pages parsed\n",
      "74/186 pages parsed\n",
      "75/186 pages parsed\n",
      "76/186 pages parsed\n",
      "77/186 pages parsed\n",
      "78/186 pages parsed\n",
      "79/186 pages parsed\n",
      "80/186 pages parsed\n",
      "81/186 pages parsed\n",
      "82/186 pages parsed\n",
      "83/186 pages parsed\n",
      "84/186 pages parsed\n",
      "85/186 pages parsed\n",
      "86/186 pages parsed\n",
      "87/186 pages parsed\n",
      "88/186 pages parsed\n",
      "89/186 pages parsed\n",
      "90/186 pages parsed\n",
      "91/186 pages parsed\n",
      "92/186 pages parsed\n",
      "93/186 pages parsed\n",
      "94/186 pages parsed\n",
      "95/186 pages parsed\n",
      "96/186 pages parsed\n",
      "97/186 pages parsed\n",
      "98/186 pages parsed\n",
      "99/186 pages parsed\n",
      "100/186 pages parsed\n",
      "101/186 pages parsed\n",
      "102/186 pages parsed\n",
      "103/186 pages parsed\n",
      "104/186 pages parsed\n",
      "105/186 pages parsed\n",
      "106/186 pages parsed\n",
      "107/186 pages parsed\n",
      "108/186 pages parsed\n",
      "109/186 pages parsed\n",
      "110/186 pages parsed\n",
      "111/186 pages parsed\n",
      "112/186 pages parsed\n",
      "113/186 pages parsed\n",
      "114/186 pages parsed\n",
      "115/186 pages parsed\n",
      "116/186 pages parsed\n",
      "117/186 pages parsed\n",
      "118/186 pages parsed\n",
      "119/186 pages parsed\n",
      "120/186 pages parsed\n",
      "121/186 pages parsed\n",
      "122/186 pages parsed\n",
      "123/186 pages parsed\n",
      "124/186 pages parsed\n",
      "125/186 pages parsed\n",
      "126/186 pages parsed\n",
      "127/186 pages parsed\n",
      "128/186 pages parsed\n",
      "129/186 pages parsed\n",
      "130/186 pages parsed\n",
      "131/186 pages parsed\n",
      "132/186 pages parsed\n",
      "133/186 pages parsed\n",
      "134/186 pages parsed\n",
      "135/186 pages parsed\n",
      "136/186 pages parsed\n",
      "137/186 pages parsed\n",
      "138/186 pages parsed\n",
      "139/186 pages parsed\n",
      "140/186 pages parsed\n",
      "141/186 pages parsed\n",
      "142/186 pages parsed\n",
      "143/186 pages parsed\n",
      "144/186 pages parsed\n",
      "145/186 pages parsed\n",
      "146/186 pages parsed\n",
      "147/186 pages parsed\n",
      "148/186 pages parsed\n",
      "149/186 pages parsed\n",
      "150/186 pages parsed\n",
      "151/186 pages parsed\n",
      "152/186 pages parsed\n",
      "153/186 pages parsed\n",
      "154/186 pages parsed\n",
      "155/186 pages parsed\n",
      "156/186 pages parsed\n",
      "157/186 pages parsed\n",
      "158/186 pages parsed\n",
      "159/186 pages parsed\n",
      "160/186 pages parsed\n",
      "161/186 pages parsed\n",
      "162/186 pages parsed\n",
      "163/186 pages parsed\n",
      "164/186 pages parsed\n",
      "165/186 pages parsed\n",
      "166/186 pages parsed\n",
      "167/186 pages parsed\n",
      "168/186 pages parsed\n",
      "169/186 pages parsed\n",
      "170/186 pages parsed\n",
      "171/186 pages parsed\n",
      "172/186 pages parsed\n",
      "173/186 pages parsed\n",
      "174/186 pages parsed\n",
      "175/186 pages parsed\n",
      "176/186 pages parsed\n",
      "177/186 pages parsed\n",
      "178/186 pages parsed\n",
      "179/186 pages parsed\n",
      "180/186 pages parsed\n",
      "181/186 pages parsed\n",
      "182/186 pages parsed\n",
      "183/186 pages parsed\n",
      "184/186 pages parsed\n",
      "185/186 pages parsed\n",
      "186/186 pages parsed\n",
      "0:08:23.445226\n"
     ]
    }
   ],
   "source": [
    "# scraping for British Gas from Trustpilot\n",
    "BG_address = \"https://uk.trustpilot.com/review/www.britishgas.co.uk?page=\"\n",
    "# BG_page = 5 # testing for 5 pages\n",
    "BG_page = 186\n",
    "\n",
    "# time took for code to run\n",
    "startTime = datetime.now()\n",
    "BG_df = BG_scrape(BG_address, BG_page) \n",
    "print(datetime.now() - startTime) \n",
    "\n",
    "# saved into .csv file\n",
    "BG_df.to_csv('BG.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are then saved into a csv file for future usage and reference. The next step, pre-processing is performed in preprocessing.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
